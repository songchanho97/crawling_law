"""
ì—¬ëŸ¬ '_merged.json' íŒŒì¼ì˜ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

ê·œì¹™:
1) ê°™ì€ idë¥¼ ê°€ì§„ í•­ëª© ì¤‘ 'refs'ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²ƒì„ ìš°ì„ í•˜ì—¬ 1ê°œë§Œ ë‚¨ê¹ë‹ˆë‹¤.
2) ëª¨ë“  ì¤‘ë³µ í•­ëª©ì˜ 'refs'ê°€ ë¹„ì–´ìˆë‹¤ë©´, ê°€ì¥ ë¨¼ì € ë‚˜ì˜¨ í•­ëª©ì„ ë‚¨ê¹ë‹ˆë‹¤.
3) idê°€ ì—†ê±°ë‚˜ í˜•ì‹ì´ ë§ì§€ ì•ŠëŠ” í•­ëª©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.

- ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ì„ FILES_TO_PROCESS ë¦¬ìŠ¤íŠ¸ì— ì •ì˜í•©ë‹ˆë‹¤.
- ê° íŒŒì¼ì— ëŒ€í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
  - ì…ë ¥: {file_base}_merged.json
  - ì¶œë ¥: {file_base}_dedup.json
"""

import json
import os
from typing import Any, Dict, List

# ====================================
# ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
# ====================================
# ì—¬ê¸°ì— ì²˜ë¦¬í•  íŒŒì¼ì˜ ê¸°ë³¸ ê²½ë¡œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
# ì˜ˆ: "./data/ì‚°ì—…ì•ˆì „ë³´ê±´ë²•_ì‹œí–‰ë ¹"
# --------------------------------------------------------------------------
FILES_TO_PROCESS = [
    "./data/ê³ ì‹œë°ì˜ˆê·œ/í•´ì²´ê³µì‚¬í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ì¶”ë½ì¬í•´ë°©ì§€í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ìì²´ì‹¬ì‚¬ ë° í™•ì¸ì—…ì²´ ì§€ì •ëŒ€ìƒ ê±´ì„¤ì—…ì²´ ê³ ì‹œ",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ë³´í˜¸êµ¬ ììœ¨ì•ˆì „í™•ì¸ ê³ ì‹œ",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ê±´ì„¤ì—… ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ì¤‘ ì§€ë„ì‚¬ê°€ í‰ê°€Â·í™•ì¸ í•  ìˆ˜ ìˆëŠ” ëŒ€ìƒ ê±´ì„¤ê³µì‚¬ì˜ ë²”ìœ„ ë° ì§€ë„ì‚¬ì˜ ìš”ê±´",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ê°€ì„¤ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ë°©í˜¸ì¥ì¹˜ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
    # "./data/ì•ˆì „ì¸ì¦Â·ììœ¨ì•ˆì „í™•ì¸ì‹ ê³ ì˜ ì ˆì°¨ì— ê´€í•œ ê³ ì‹œ",
    # "./data/ë°©í˜¸ì¥ì¹˜ ììœ¨ì•ˆì „ê¸°ì¤€ ê³ ì‹œ",
    # "./data/êµ´ì°©ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
    # "./data/ìœ„í—˜ê¸°ê³„Â·ê¸°êµ¬ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
    # "./data/ê±´ì„¤ì—…ì²´ì˜ ì‚°ì—…ì¬í•´ì˜ˆë°©í™œë™ ì‹¤ì  í‰ê°€ê¸°ì¤€",
    # "./data/ì•ˆì „ë³´ê±´êµìœ¡ê·œì •",
    # "./data/ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ëŒ€ì¥ì˜ ì‘ì„± ë“±ì— ê´€í•œ ê³ ì‹œ",
    # "./data/ê±´ì„¤ì—… ì‚°ì—…ì•ˆì „ë³´ê±´ê´€ë¦¬ë¹„ ê³„ìƒ ë° ì‚¬ìš©ê¸°ì¤€",
    # "./data/ì‚°ì—…ì¬í•´ì˜ˆë°©ì‹œì„¤ìê¸ˆ ìœµìê¸ˆ ì§€ì›ì‚¬ì—… ë° í´ë¦°ì‚¬ì—…ì¥ ì¡°ì„±ì§€ì›ì‚¬ì—… ìš´ì˜ê·œì •",
]


# ====================================
# ë„ìš°ë¯¸ í•¨ìˆ˜
# ====================================
def refs_nonempty(item: Dict[str, Any]) -> bool:
    """'refs' í•„ë“œê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ë¦¬ìŠ¤íŠ¸ì´ë©´ Trueë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not isinstance(item, dict):
        return False
    refs = item.get("refs", [])
    return isinstance(refs, list) and len(refs) > 0


# ====================================
# í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# ====================================
def deduplicate_json_file(file_base: str) -> Dict[str, Any]:
    """ë‹¨ì¼ JSON íŒŒì¼ì˜ ì¤‘ë³µì„ ì œê±°í•˜ê³  í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    in_path = f"{file_base}_merged.json"
    out_path = f"{file_base}_dedup.json"

    # 1) ì…ë ¥ íŒŒì¼ í™•ì¸
    if not os.path.exists(in_path):
        print(f"  [SKIP] ì…ë ¥ íŒŒì¼ '{in_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # 2) ë°ì´í„° ë¡œë“œ
    with open(in_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        raise ValueError("ì…ë ¥ JSONì˜ ë£¨íŠ¸ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    # 3) ì¤‘ë³µ ì œê±° ë¡œì§
    kept: List[Any] = []
    idx_by_id: Dict[str, int] = {}
    has_nonempty_by_id: Dict[str, bool] = {}

    stats = {
        "replaced": 0,
        "skipped": 0,
        "orphans": 0,
        "total_in": len(data),
        "total_out": 0,
    }

    for item in data:
        if not isinstance(item, dict) or "id" not in item:
            kept.append(item)
            stats["orphans"] += 1
            continue

        _id = item["id"]
        cur_has_refs = refs_nonempty(item)

        if _id not in idx_by_id:
            # ìµœì´ˆ ë“±ì¥: ì¼ë‹¨ ì €ì¥
            kept.append(item)
            idx = len(kept) - 1
            idx_by_id[_id] = idx
            has_nonempty_by_id[_id] = cur_has_refs
        else:
            # ì¤‘ë³µ ë“±ì¥: êµì²´ ì—¬ë¶€ íŒë‹¨
            idx = idx_by_id[_id]
            prev_has_refs = has_nonempty_by_id[_id]

            if not prev_has_refs and cur_has_refs:
                # ê¸°ì¡´ í•­ëª©(refs ì—†ìŒ)ì„ ìƒˆ í•­ëª©(refs ìˆìŒ)ìœ¼ë¡œ êµì²´
                kept[idx] = item
                has_nonempty_by_id[_id] = True
                stats["replaced"] += 1
            else:
                # ê¸°ì¡´ í•­ëª© ìœ ì§€ (ê¸°ì¡´ì— refsê°€ ìˆê±°ë‚˜, ë‘˜ ë‹¤ refsê°€ ì—†ëŠ” ê²½ìš°)
                stats["skipped"] += 1

    # 4) ê²°ê³¼ ì €ì¥ ë° í†µê³„ ë°˜í™˜
    stats["total_out"] = len(kept)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(kept, f, ensure_ascii=False, indent=2)

    stats["out_path"] = out_path
    return stats


# ====================================
# ì‹¤í–‰
# ====================================
def main():
    print("===== JSON ì¤‘ë³µ ì œê±° ì‘ì—… ì‹œì‘ =====")
    grand_total_in = 0
    grand_total_out = 0

    for file_base in FILES_TO_PROCESS:
        file_disp_name = os.path.basename(file_base)
        print(f"\nâ–¶ï¸  '{file_disp_name}' ì²˜ë¦¬ ì‹œì‘...")
        try:
            result = deduplicate_json_file(file_base)
            if result:
                grand_total_in += result["total_in"]
                grand_total_out += result["total_out"]
                print(f"  âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ â†’ {result['out_path']}")
                print(f"    - ì…ë ¥: {result['total_in']} â†’ ì¶œë ¥: {result['total_out']}")
                print(
                    f"    - êµì²´: {result['replaced']}, ê±´ë„ˆëœ€: {result['skipped']}, ë¹„ì •í˜•: {result['orphans']}"
                )
        except Exception as e:
            print(f"  ğŸš¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("\n" + "=" * 20 + " ëª¨ë“  ì‘ì—… ì™„ë£Œ " + "=" * 20)
    print(f"ì´ {len(FILES_TO_PROCESS)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ.")
    print(f"ì „ì²´ ì…ë ¥ í•­ëª© ìˆ˜: {grand_total_in}")
    print(f"ì „ì²´ ì¶œë ¥ í•­ëª© ìˆ˜: {grand_total_out}")
    print(f"ì „ì²´ ì œê±°ëœ í•­ëª© ìˆ˜: {grand_total_in - grand_total_out}")


if __name__ == "__main__":
    main()
