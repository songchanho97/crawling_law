import re
import json
import pandas as pd
from typing import List, Dict, Any, Tuple, Optional
import csv
from collections import defaultdict

# ------------ CSV ë¡œë”© ë³´ê°•(ì¸ì½”ë”©/êµ¬ë¶„ì ìë™ ì‹œë„) ------------
CANDIDATE_ENCODINGS = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin1"]
CANDIDATE_SEPARATORS = [
    None,
    ",",
    "\t",
    ";",
    "|",
]  # None=êµ¬ë¶„ì ìë™ì¶”ì • (python engine í•„ìš”)


def read_csv_safely(path: str, **kwargs) -> pd.DataFrame:
    last_err = None
    for enc in CANDIDATE_ENCODINGS:
        for sep in CANDIDATE_SEPARATORS:
            try:
                df = pd.read_csv(
                    path,
                    encoding=enc,
                    sep=sep,
                    engine="python",
                    dtype=str,
                    quoting=csv.QUOTE_MINIMAL,
                    **kwargs,
                )
                # ìµœì†Œ ì»¬ëŸ¼ ê²€ì‚¬: ì¡°/ë§í¬ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ì‹œë„
                if not {"ì¡°", "ë§í¬ í…ìŠ¤íŠ¸"}.issubset(set(df.columns)):
                    last_err = ValueError(
                        f"êµ¬ë¶„ì/ì¸ì½”ë”© ì¶”ì • ì‹¤íŒ¨(ì»¬ëŸ¼ ëˆ„ë½): enc={enc}, sep={sep}"
                    )
                    continue
                print(
                    f"[INFO] CSV ì¸ì½”ë”©={enc}, sep={'auto' if sep is None else repr(sep)}"
                )
                return df
            except Exception as e:
                last_err = e
                continue
    raise last_err


# ------------ ì •ê·œí™” ìœ í‹¸ ------------
STRIP_CHARS = "ã€Œã€[](){}ã€ˆã€‰ã€Šã€‹ã€ã€‘'\"â€œâ€â€˜â€™Â·ã†,.;:"

WS_RE = re.compile(r"\s+")


def norm_for_match(s: str) -> str:
    """ë§¤ì¹­ìš© ì •ê·œí™”: ê´„í˜¸ë¥˜/êµ¬ë‘ì  ì œê±° + ê³µë°± ì œê±°"""
    if s is None:
        return ""
    t = s
    for ch in STRIP_CHARS:
        t = t.replace(ch, "")
    t = WS_RE.sub("", t)
    return t


def canonicalize_article_key(val: str) -> str:
    """
    CSV 'ì¡°' ê°’ì„ ì •ê·œí™”:
    - '4_2' ìœ ì§€(ìš°ì„ )
    - '4ì˜2' ìœ ì§€
    - ìˆ«ìì²˜ëŸ¼ ë³´ì´ë©´ 'ì •ìˆ˜ë¬¸ìì—´'ë¡œ
    """
    if val is None:
        return ""
    s = str(val).strip()
    if "_" in s or "ì˜" in s:
        return s
    # '2.0' -> '2'
    if re.fullmatch(r"\d+(?:\.0+)?", s):
        return str(int(float(s)))
    return s


# ------------ JSON â†’ ì¡°/í•­/í˜¸ ì¸ë±ìŠ¤ êµ¬ì¶• ------------
def load_law_json(path: str) -> List[Dict[str, Any]]:
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, list):
        raise ValueError("JSON ìµœìƒìœ„ëŠ” listì—¬ì•¼ í•©ë‹ˆë‹¤.")
    return data


def build_article_index(nodes: List[Dict[str, Any]]):
    """
    JSON ë…¸ë“œ(ì¡°/í•­/í˜¸)ë¥¼ ì´ìš©í•´ ë§¤ì¹­ìš© ì¸ë±ìŠ¤ë¥¼ ë§Œë“ ë‹¤.
    ë°˜í™˜:
      articles_by_key: dict[str, dict]  # '4', '4ì˜2', '4_2' ë“±ìœ¼ë¡œ ì ‘ê·¼
      cursors: dict[str, {'seg_idx':0,'offset':0}]  # ì¡°ë³„ ìŠ¤ìº” ì»¤ì„œ
    ê° article êµ¬ì¡°:
      {
        'id': 'ì‚°ì—…ì•ˆì „ë³´ê±´ë²•-4_2',
        'number': '4ì˜2',
        'underscore': '4_2',
        'base': '4',
        'segments': [
            {'scope':'ì¡°','hang':None,'ho':None,'text':..., 'text_norm':...},  # ì¡° ë³¸ë¬¸ì´ ìˆì„ ë•Œë§Œ
            {'scope':'í•­','hang':1,'ho':None,'text':..., 'text_norm':...},
            {'scope':'í˜¸','hang':1,'ho':1,  'text':..., 'text_norm':...},
            ...
        ]
      }
    """
    nodes_by_id = {n["id"]: n for n in nodes}
    # ì¡° ëª©ë¡ë§Œ ì¶”ì¶œ
    articles = [n for n in nodes if n.get("level") == "ì¡°"]

    def number_to_underscore(num: str) -> str:
        # '4ì˜2' â†’ '4_2'
        m = re.fullmatch(r"(\d+)(?:ì˜(\d+))?", num)
        if not m:
            return num
        base, sub = m.group(1), m.group(2)
        return f"{base}_{sub}" if sub else base

    def number_base(num: str) -> str:
        m = re.fullmatch(r"(\d+)(?:ì˜(\d+))?", num)
        return m.group(1) if m else num

    articles_by_key: Dict[str, Dict[str, Any]] = {}
    base_buckets: Dict[str, List[Dict[str, Any]]] = defaultdict(list)

    for a in articles:
        aid = a["id"]
        num = a.get("number", "")
        underscore = number_to_underscore(num)
        base = number_base(num)

        # ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì„± (ì¡° ë³¸ë¬¸ì´ ìˆìœ¼ë©´ ë„£ê¸°)
        segments: List[Dict[str, Any]] = []
        a_text = (a.get("text") or "").strip()
        if a_text and a_text not in ("", None):
            segments.append(
                {
                    "scope": "ì¡°",
                    "hang": None,
                    "ho": None,
                    "text": a_text,
                    "text_norm": norm_for_match(a_text),
                }
            )

        # í•­/í˜¸ ì¶”ê°€: Children_id ìˆœíšŒ(ê¸°ì¡´ ìˆœì„œ ìœ ì§€)
        for hid in a.get("Children_id", []) or []:
            hnode = nodes_by_id.get(hid)
            if not hnode or hnode.get("level") != "í•­":
                continue
            h_txt = (hnode.get("text") or "").strip()
            h_no = (
                int(hnode.get("number"))
                if str(hnode.get("number", "")).isdigit()
                else None
            )
            if h_txt:
                segments.append(
                    {
                        "scope": "í•­",
                        "hang": h_no,
                        "ho": None,
                        "text": h_txt,
                        "text_norm": norm_for_match(h_txt),
                    }
                )
            # í˜¸
            for oid in hnode.get("Children_id", []) or []:
                onode = nodes_by_id.get(oid)
                if not onode or onode.get("level") != "í˜¸":
                    continue
                o_txt = (onode.get("text") or "").strip()
                o_no = (
                    int(onode.get("number"))
                    if str(onode.get("number", "")).isdigit()
                    else None
                )
                if o_txt:
                    segments.append(
                        {
                            "scope": "í˜¸",
                            "hang": h_no,
                            "ho": o_no,
                            "text": o_txt,
                            "text_norm": norm_for_match(o_txt),
                        }
                    )

        article = {
            "id": aid,
            "number": num,  # ì˜ˆ: '4ì˜2'
            "underscore": underscore,  # ì˜ˆ: '4_2'
            "base": base,  # ì˜ˆ: '4'
            "segments": segments,
        }

        # í‚¤ ë“±ë¡: '4ì˜2', '4_2' ë‘˜ ë‹¤ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ
        articles_by_key[num] = article
        articles_by_key[underscore] = article
        base_buckets[base].append(article)

    # ì¡°ë³„ ì»¤ì„œ
    cursors = {
        art["underscore"]: {"seg_idx": 0, "offset": 0}
        for art in {v["underscore"]: v for v in articles_by_key.values()}.values()
    }

    return articles_by_key, base_buckets, cursors


# ------------ ë§¤ì¹­ ë¡œì§(ì¡°ë³„ ì»¤ì„œ) ------------
def match_with_cursor(article: Dict[str, Any], link_text: str, cursor: Dict[str, int]):
    """
    article['segments']ì—ì„œ link_text(ì •ê·œí™”)ë¥¼ cursorë¶€í„° ìˆœì°¨ ê²€ìƒ‰.
    ë°˜í™˜: (hang, ho, scope, new_cursor)
    scope âˆˆ {'í˜¸','í•­','ì¡°','ë¯¸ê²€ì¶œ'}
    """
    segs = article.get("segments", [])
    if not segs or not link_text or not norm_for_match(link_text):
        return None, None, "ë¯¸ê²€ì¶œ", cursor

    q = norm_for_match(link_text)
    seg_idx = cursor.get("seg_idx", 0)
    offset = cursor.get("offset", 0)

    # 1íŒ¨ìŠ¤: cursorâ†’ë
    for i in range(seg_idx, len(segs)):
        s = segs[i]
        pos = s["text_norm"].find(q, offset if i == seg_idx else 0)
        if pos >= 0:
            new_off = pos + len(q)
            if new_off >= len(s["text_norm"]):
                new_cursor = {"seg_idx": i + 1, "offset": 0}
            else:
                new_cursor = {"seg_idx": i, "offset": new_off}
            return (s.get("hang"), s.get("ho"), s["scope"], new_cursor)

    # 2íŒ¨ìŠ¤: ì²˜ìŒâ†’ë (ì•ˆì „ì¥ì¹˜)
    for i in range(0, len(segs)):
        s = segs[i]
        pos = s["text_norm"].find(q)
        if pos >= 0:
            new_off = pos + len(q)
            if new_off >= len(s["text_norm"]):
                new_cursor = {"seg_idx": i + 1, "offset": 0}
            else:
                new_cursor = {"seg_idx": i, "offset": new_off}
            return (s.get("hang"), s.get("ho"), s["scope"], new_cursor)

    return None, None, "ë¯¸ê²€ì¶œ", cursor


# ------------ ë©”ì¸ ì‹¤í–‰ ë¡œì§ì„ í•¨ìˆ˜ë¡œ ì „í™˜ ------------
def process_law_file(file_name: str):
    """í•˜ë‚˜ì˜ ë²•ë ¹ íŒŒì¼ ì„¸íŠ¸(json, csv)ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê²°ê³¼ csvë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    print(f"\nâ–¶ï¸ '{file_name}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")

    # ------------ ê²½ë¡œ ì„¤ì • (í•¨ìˆ˜ ë‚´ë¶€ë¡œ ì´ë™) ------------
    JSON_PATH = f"./data/ê³ ì‹œë°ì˜ˆê·œ/{file_name}_í°í‹€.json"
    CSV_PATH = f"./data/ê³ ì‹œë°ì˜ˆê·œ/{file_name}_data.csv"
    OUT_CSV_PATH = f"./data/ê³ ì‹œë°ì˜ˆê·œ/{file_name}_í•­_í˜¸.csv"

    # 1) JSON ì½ê¸°
    nodes = load_law_json(JSON_PATH)
    articles_by_key, base_buckets, cursors = build_article_index(nodes)
    print(
        f" INFO: ì¡°(ê¸°ì‚¬) ê°œìˆ˜: {len({a['underscore'] for a in articles_by_key.values()})}"
    )

    # 2) CSV ì½ê¸°
    df = read_csv_safely(CSV_PATH)
    if not {"ì¡°", "ë§í¬ í…ìŠ¤íŠ¸"}.issubset(set(df.columns)):
        raise ValueError("CSVì— 'ì¡°', 'ë§í¬ í…ìŠ¤íŠ¸' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # 3) í–‰ë³„ ë§¤ì¹­
    hang_col: List[Optional[int]] = []
    ho_col: List[Optional[int]] = []
    scope_col: List[str] = []
    matched_article_num: List[str] = []

    for _, row in df.iterrows():
        raw_article = row.get("ì¡°", "")
        link_text = (row.get("ë§í¬ í…ìŠ¤íŠ¸") or "").strip()

        if not str(raw_article).strip() or not link_text:
            hang_col.append(None)
            ho_col.append(None)
            scope_col.append("ë¯¸ê²€ì¶œ")
            matched_article_num.append("")
            continue

        key = canonicalize_article_key(raw_article)
        art = articles_by_key.get(key)

        if art is None and key.isdigit():
            cands = base_buckets.get(key, [])
            art = cands[0] if cands else None

        if art is None:
            hang_col.append(None)
            ho_col.append(None)
            scope_col.append("ë¯¸ê²€ì¶œ")
            matched_article_num.append("")
            continue

        cursor_key = art["underscore"]
        cur = cursors.get(cursor_key, {"seg_idx": 0, "offset": 0})
        h, o, scope, new_cur = match_with_cursor(art, link_text, cur)
        cursors[cursor_key] = new_cur

        hang_col.append(h if scope in ("í•­", "í˜¸") else None)
        ho_col.append(o if scope == "í˜¸" else None)
        scope_col.append(scope)
        matched_article_num.append(art["number"])

    # 4) CSV ê²°ê³¼ ì €ì¥
    df_out = df.copy()
    insert_pos = df_out.columns.get_loc("ì¡°") + 1
    df_out.insert(insert_pos, "í•­", hang_col)
    df_out.insert(insert_pos + 1, "í˜¸", ho_col)
    df_out["ë§¤ì¹­ë²”ìœ„"] = scope_col
    df_out["ë§¤ì¹­ì¡°ë¬¸ìì—´"] = matched_article_num

    df_out.to_csv(OUT_CSV_PATH, index=False, encoding="utf-8-sig")
    print(f"âœ… [ì™„ë£Œ] ì €ì¥ ì™„ë£Œ â†’ {OUT_CSV_PATH}")
    print(f"     ì´ í–‰ìˆ˜={len(df_out)}, ë¯¸ê²€ì¶œ={(df_out['ë§¤ì¹­ë²”ìœ„']=='ë¯¸ê²€ì¶œ').sum()}")


# ------------ ë©”ì¸ ì‹¤í–‰ë¶€ (ë°˜ë³µë¬¸ìœ¼ë¡œ ë³€ê²½) ------------
if __name__ == "__main__":
    # ğŸ”½ ì—¬ê¸°ì— ì²˜ë¦¬í•  íŒŒì¼ ì´ë¦„ ëª©ë¡ì„ ì¶”ê°€í•˜ì„¸ìš”. (í™•ì¥ì ì œì™¸)
    file_names_to_process = [
        "í•´ì²´ê³µì‚¬í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
        "ì¶”ë½ì¬í•´ë°©ì§€í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
        # "ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ìì²´ì‹¬ì‚¬ ë° í™•ì¸ì—…ì²´ ì§€ì •ëŒ€ìƒ ê±´ì„¤ì—…ì²´ ê³ ì‹œ",
        "ë³´í˜¸êµ¬ ììœ¨ì•ˆì „í™•ì¸ ê³ ì‹œ",
        "ê±´ì„¤ì—… ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ì¤‘ ì§€ë„ì‚¬ê°€ í‰ê°€Â·í™•ì¸ í•  ìˆ˜ ìˆëŠ” ëŒ€ìƒ ê±´ì„¤ê³µì‚¬ì˜ ë²”ìœ„ ë° ì§€ë„ì‚¬ì˜ ìš”ê±´",
        "ê°€ì„¤ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
        "ë°©í˜¸ì¥ì¹˜ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
        # "ì•ˆì „ì¸ì¦Â·ììœ¨ì•ˆì „í™•ì¸ì‹ ê³ ì˜ ì ˆì°¨ì— ê´€í•œ ê³ ì‹œ",
        # "ë°©í˜¸ì¥ì¹˜ ììœ¨ì•ˆì „ê¸°ì¤€ ê³ ì‹œ",
        # "êµ´ì°©ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
        # "ìœ„í—˜ê¸°ê³„Â·ê¸°êµ¬ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
        # "ê±´ì„¤ì—…ì²´ì˜ ì‚°ì—…ì¬í•´ì˜ˆë°©í™œë™ ì‹¤ì  í‰ê°€ê¸°ì¤€",
        # "ì•ˆì „ë³´ê±´êµìœ¡ê·œì •",
        # "ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ëŒ€ì¥ì˜ ì‘ì„± ë“±ì— ê´€í•œ ê³ ì‹œ",
        # "ê±´ì„¤ì—… ì‚°ì—…ì•ˆì „ë³´ê±´ê´€ë¦¬ë¹„ ê³„ìƒ ë° ì‚¬ìš©ê¸°ì¤€",
        # "ì‚°ì—…ì¬í•´ì˜ˆë°©ì‹œì„¤ìê¸ˆ ìœµìê¸ˆ ì§€ì›ì‚¬ì—… ë° í´ë¦°ì‚¬ì—…ì¥ ì¡°ì„±ì§€ì›ì‚¬ì—… ìš´ì˜ê·œì •"
    ]

    for name in file_names_to_process:
        try:
            process_law_file(name)
        except FileNotFoundError as e:
            print(f"âŒ [ì˜¤ë¥˜] '{name}' ì²˜ë¦¬ ì¤‘ íŒŒì¼ ì—†ìŒ: {e}")
        except Exception as e:
            print(f"âŒ [ì˜¤ë¥˜] '{name}' ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    print("\nğŸ‰ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
