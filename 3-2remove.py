"""
ì—¬ëŸ¬ ë²•ë ¹ JSON íŒŒì¼ì— ëŒ€í•´, ê°ê°ì— í•´ë‹¹í•˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì½ì–´
JSON ë…¸ë“œì˜ 'refs' í•„ë“œë¥¼ ì±„ìš°ëŠ” ìŠ¤í¬ë¦½íŠ¸.

- ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ì„ FILES_TO_PROCESS ë¦¬ìŠ¤íŠ¸ì— ì •ì˜í•©ë‹ˆë‹¤.
- ê° íŒŒì¼ ìŒì— ëŒ€í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
  - ì…ë ¥: {file_base}_í°í‹€.json, {file_base}_Ref_labeled_with_json.xlsx
  - ì¶œë ¥: {file_base}_refs_filled.json
- ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ í›„, ê±´ë„ˆë›´ í–‰ë“¤ì˜ ëª©ë¡ì„ í†µí•©ëœ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import json
import pandas as pd
import re
import os
from typing import Any, Dict, List, Optional

# ====================================
# ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
# ====================================
# ì—¬ê¸°ì— ì²˜ë¦¬í•  íŒŒì¼ì˜ ê¸°ë³¸ ê²½ë¡œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
# ì˜ˆ: "./data/ì‚°ì—…ì•ˆì „ë³´ê±´ë²•_ì‹œí–‰ë ¹"
# --------------------------------------------------------------------------
FILES_TO_PROCESS = [
    "./data/ê³ ì‹œë°ì˜ˆê·œ/í•´ì²´ê³µì‚¬í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ì¶”ë½ì¬í•´ë°©ì§€í‘œì¤€ì•ˆì „ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ìì²´ì‹¬ì‚¬ ë° í™•ì¸ì—…ì²´ ì§€ì •ëŒ€ìƒ ê±´ì„¤ì—…ì²´ ê³ ì‹œ",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ë³´í˜¸êµ¬ ììœ¨ì•ˆì „í™•ì¸ ê³ ì‹œ",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ê±´ì„¤ì—… ìœ í•´Â·ìœ„í—˜ë°©ì§€ê³„íšì„œ ì¤‘ ì§€ë„ì‚¬ê°€ í‰ê°€Â·í™•ì¸ í•  ìˆ˜ ìˆëŠ” ëŒ€ìƒ ê±´ì„¤ê³µì‚¬ì˜ ë²”ìœ„ ë° ì§€ë„ì‚¬ì˜ ìš”ê±´",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ê°€ì„¤ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
    "./data/ê³ ì‹œë°ì˜ˆê·œ/ë°©í˜¸ì¥ì¹˜ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
    # "./data/ì•ˆì „ì¸ì¦Â·ììœ¨ì•ˆì „í™•ì¸ì‹ ê³ ì˜ ì ˆì°¨ì— ê´€í•œ ê³ ì‹œ",
    # "./data/ë°©í˜¸ì¥ì¹˜ ììœ¨ì•ˆì „ê¸°ì¤€ ê³ ì‹œ",
    # "./data/êµ´ì°©ê³µì‚¬ í‘œì¤€ì•ˆì „ ì‘ì—…ì§€ì¹¨",
    # "./data/ìœ„í—˜ê¸°ê³„Â·ê¸°êµ¬ ì•ˆì „ì¸ì¦ ê³ ì‹œ",
    # "./data/ê±´ì„¤ì—…ì²´ì˜ ì‚°ì—…ì¬í•´ì˜ˆë°©í™œë™ ì‹¤ì  í‰ê°€ê¸°ì¤€",
    # "./data/ì•ˆì „ë³´ê±´êµìœ¡ê·œì •",
    # "./data/ê±´ì„¤ê³µì‚¬ ì•ˆì „ë³´ê±´ëŒ€ì¥ì˜ ì‘ì„± ë“±ì— ê´€í•œ ê³ ì‹œ",
    # "./data/ê±´ì„¤ì—… ì‚°ì—…ì•ˆì „ë³´ê±´ê´€ë¦¬ë¹„ ê³„ìƒ ë° ì‚¬ìš©ê¸°ì¤€",
    # "./data/ì‚°ì—…ì¬í•´ì˜ˆë°©ì‹œì„¤ìê¸ˆ ìœµìê¸ˆ ì§€ì›ì‚¬ì—… ë° í´ë¦°ì‚¬ì—…ì¥ ì¡°ì„±ì§€ì›ì‚¬ì—… ìš´ì˜ê·œì •",
]

# ====================================
# ì „ì—­ ì„¤ì •
# ====================================
# í†µí•© ë¡œê·¸ CSV íŒŒì¼ëª…
SKIPPED_NO_NODE_CSV = "all_rows_skipped_no_node.csv"
SKIPPED_EMPTY_LABEL_OR_JSON_CSV = "all_rows_skipped_empty_label_or_json.csv"


# ====================================
# ë„ìš°ë¯¸ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ====================================
def ensure_list(obj) -> List:
    if obj is None:
        return []
    if isinstance(obj, list):
        return obj
    return [obj]


def pick_label(row: pd.Series) -> Optional[str]:
    val1 = str(row.get("ë§í¬ í…ìŠ¤íŠ¸", "") or "").strip()
    if val1:
        return val1
    val2 = str(row.get("ë§í¬ í…ìŠ¤íŠ¸(ì›ë³¸)", "") or "").strip()
    return val2 if val2 else None


def parse_link_json(cell_value: Any) -> List[Dict[str, Any]]:
    if cell_value is None:
        return []
    if isinstance(cell_value, (list, dict)):
        return ensure_list(cell_value)
    text = str(cell_value).strip()
    if not text:
        return []
    try:
        return ensure_list(json.loads(text))
    except json.JSONDecodeError:
        try:
            return ensure_list(json.loads(text.replace("'", '"')))
        except Exception:
            return []


def guess_law_title(item: Dict[str, Any]) -> str:
    lt = str(item.get("law_title", "") or "").strip()
    if lt:
        return lt
    tx = str(item.get("text", "") or "").strip()
    if tx:
        return tx
    rid = str(item.get("id", "") or "").strip()
    m = re.match(r"^([^-]+)-", rid)
    return m.group(1) if m else (rid or "")


def ref_key_for_dedup(r: Dict[str, Any]) -> tuple:
    return (r.get("label", ""), r.get("id", ""), r.get("law_title", ""))


# ====================================
# í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# ====================================
def process_file(file_base: str, sheet_name: Any = 0) -> Dict[str, Any]:
    """ë‹¨ì¼ íŒŒì¼ ìŒ(JSON, Excel)ì„ ì²˜ë¦¬í•˜ì—¬ refsë¥¼ ì±„ìš°ê³  í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    json_in_path = f"{file_base}_í°í‹€.json"
    excel_path = f"{file_base}_Ref_labeled_with_json.xlsx"
    json_out_path = f"{file_base}_refs_filled.json"

    # 1) ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(json_in_path) or not os.path.exists(excel_path):
        print(f"  [SKIP] ì…ë ¥ íŒŒì¼(.json ë˜ëŠ” .xlsx)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # 2) JSON ë° Excel ë¡œë“œ
    with open(json_in_path, "r", encoding="utf-8") as f:
        nodes = json.load(f)

    id_to_idx: Dict[str, int] = {
        str(n.get("id", "")).strip(): i
        for i, n in enumerate(nodes)
        if str(n.get("id", "")).strip()
    }

    df = pd.read_excel(excel_path, sheet_name=sheet_name, dtype=str)

    # 3) ì²˜ë¦¬
    updated_nodes = 0
    added_refs = 0
    skipped_no_node_rows = []
    skipped_empty_rows = []

    for r_idx, row in df.iterrows():
        nid = str(row.get("id", "") or "").strip()
        if not nid:
            continue

        label = pick_label(row)
        link_json = parse_link_json(row.get("ë§í¬ë°ì´í„°_JSON"))

        if not label or not link_json:
            skipped_empty_rows.append(
                {
                    "source_file": os.path.basename(file_base),
                    "row_index": r_idx,
                    "id": nid,
                    "label": label,
                    "json_preview": str(row.get("ë§í¬ë°ì´í„°_JSON", ""))[:100],
                }
            )
            continue

        idx = id_to_idx.get(nid)
        if idx is None:
            skipped_no_node_rows.append(
                {
                    "source_file": os.path.basename(file_base),
                    "row_index": r_idx,
                    "id": nid,
                    "label": label,
                    "json_preview": str(row.get("ë§í¬ë°ì´í„°_JSON", ""))[:100],
                }
            )
            continue

        node = nodes[idx]
        if "refs" not in node or not isinstance(node["refs"], list):
            node["refs"] = []

        before_keys = {ref_key_for_dedup(x) for x in node["refs"]}

        to_add = []
        for item in link_json:
            target_id = str(item.get("id", "") or "").strip()
            if not target_id:
                continue

            ref = {
                "label": label,
                "law_title": guess_law_title(item),
                "id": target_id,
                "relation": "",
            }

            ref_key = ref_key_for_dedup(ref)
            if ref_key not in before_keys:
                to_add.append(ref)
                before_keys.add(ref_key)

        if to_add:
            node["refs"].extend(to_add)
            updated_nodes += 1
            added_refs += len(to_add)

    # 4) ê²°ê³¼ ì €ì¥ ë° í†µê³„ ë°˜í™˜
    with open(json_out_path, "w", encoding="utf-8") as f:
        json.dump(nodes, f, ensure_ascii=False, indent=2)

    return {
        "updated_nodes": updated_nodes,
        "added_refs": added_refs,
        "skipped_no_node": skipped_no_node_rows,
        "skipped_empty": skipped_empty_rows,
        "out_path": json_out_path,
    }


# ====================================
# ì‹¤í–‰
# ====================================
def main():
    print("===== Refs ì±„ìš°ê¸° ì‘ì—… ì‹œì‘ =====")
    total_stats = {"updated": 0, "added": 0}
    all_skipped_no_node = []
    all_skipped_empty = []

    for file_base in FILES_TO_PROCESS:
        file_disp_name = os.path.basename(file_base)
        print(f"\nâ–¶ï¸  '{file_disp_name}' ì²˜ë¦¬ ì‹œì‘...")
        try:
            result = process_file(file_base)
            if result:
                total_stats["updated"] += result["updated_nodes"]
                total_stats["added"] += result["added_refs"]
                all_skipped_no_node.extend(result["skipped_no_node"])
                all_skipped_empty.extend(result["skipped_empty"])
                print(f"  âœ… ì €ì¥ ì™„ë£Œ â†’ {result['out_path']}")
                print(
                    f"    - Refs ì¶”ê°€ëœ ë…¸ë“œ: {result['updated_nodes']}, ì¶”ê°€ëœ refs ì´í•©: {result['added_refs']}"
                )
        except Exception as e:
            print(f"  ğŸš¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ìµœì¢… ìš”ì•½ ë° í†µí•© CSV ì €ì¥
    print("\n" + "=" * 20 + " ëª¨ë“  ì‘ì—… ì™„ë£Œ " + "=" * 20)
    print(f"- ì´ refs ì¶”ê°€ëœ ë…¸ë“œ ìˆ˜: {total_stats['updated']}")
    print(f"- ì´ ì¶”ê°€ëœ refs í•©ê³„: {total_stats['added']}")

    if all_skipped_no_node:
        pd.DataFrame(all_skipped_no_node).to_csv(
            SKIPPED_NO_NODE_CSV, index=False, encoding="utf-8-sig"
        )
        print(
            f"- ë§¤ì¹­ ë…¸ë“œ ì—†ìŒ í–‰: {len(all_skipped_no_node)} (CSV ì €ì¥: {SKIPPED_NO_NODE_CSV})"
        )
    else:
        print("- ë§¤ì¹­ ë…¸ë“œ ì—†ìŒ í–‰: 0")

    if all_skipped_empty:
        pd.DataFrame(all_skipped_empty).to_csv(
            SKIPPED_EMPTY_LABEL_OR_JSON_CSV, index=False, encoding="utf-8-sig"
        )
        print(
            f"- ë¹ˆ ë¼ë²¨/ë§í¬ë°ì´í„° í–‰: {len(all_skipped_empty)} (CSV ì €ì¥: {SKIPPED_EMPTY_LABEL_OR_JSON_CSV})"
        )
    else:
        print("- ë¹ˆ ë¼ë²¨/ë§í¬ë°ì´í„° í–‰: 0")


if __name__ == "__main__":
    main()
